# Trabalho de Engenharia de Dados

### Link para ajuda
[Assista aqui](https://www.youtube.com/watch?v=eOrWEsZIfKU)

### Tarefas
- Criar um ambiente PySpark e Jupyter Labs (pip, poetry, etc.), implementando Delta Lake e Apache Iceberg.
- Descrever o passo a passo para reproduzir o seu ambiente no arquivo `README` (instruções bem detalhadas, bibliotecas, versões, etc.). Utilize os recursos de markdown – código, formatação, links, etc.
- Descrever o cenário da(s) tabela(s) em um arquivo tipo notebook – modelo ER, imagens e códigos DDL – e da fonte de dados utilizada (preferência por dados públicos).
- Explique e evidencie, com exemplos, os comandos de `INSERT`, `UPDATE` e `DELETE` nas tabelas Delta e Iceberg dentro do Apache Spark.

### Organização do README
- Separe todos os cenários/exemplos do Delta Lake e Apache Iceberg.

### Prazo para entrega
**Data limite: 03/10**
